# ðŸ“Š Pattern Recognition & Machine Learning

This repository contains the implementation of the final assignment for the course **Pattern Recognition & Machine Learning** at the School of Electrical and Computer Engineering, Aristotle University of Thessaloniki.

The assignment is split into four main parts (Aâ€“D), each focusing on different aspects of statistical learning, classification, and model evaluation.

---

## ðŸ§  Part A â€“ Maximum Likelihood Classification

We develop a classifier for stress detection based on pressure metrics derived from a gaming console. The data follow a Cauchy-like distribution, and parameters are estimated using the **Maximum Likelihood Estimation (MLE)** method.

ðŸ“Œ Highlights:
- MLE parameter estimation (Î¸Ì‚)
- Log-likelihood visualization
- Discriminant function `g(x)` for classification
- Custom `Classifier` class with `.fit()` and `.predict()` methods

---

## ðŸ§  Part B â€“ Bayesian Parameter Estimation

In this part, the same classification task is approached using **Bayesian estimation** with a prior distribution on Î¸. We compute the posterior p(Î¸|D) and use it to define a new discriminant function `h(x)`.

ðŸ“Œ Highlights:
- Posterior distribution approximation using trapezoidal integration
- Comparison of MLE vs Bayesian estimation
- Updated decision boundary using posterior-based classification

---

## ðŸŒ¸ Part C â€“ Iris Flower Classification

We classify two species of the Iris dataset using:

### ðŸŒ³ Subpart 1: Decision Tree Classifier
- Trained on 50% of the samples
- Evaluation on the remaining 50%
- Depth tuning and contour decision boundary visualization

### ðŸŒ² Subpart 2: Random Forest Classifier
- 100 decision trees using bootstrap sampling
- Evaluation of performance vs. decision tree
- Study of how sampling ratio Î³ affects accuracy

---

## ðŸ“ˆ Part D â€“ Multiclass Classification with Real-World Data

Using the dataset `datasetTV.csv` with **8743 training samples and 224 features**, we build a **custom classification model** to predict stress level classes (labels 1â€“5) and evaluate on a separate test set (`datasetTest.csv` with 6955 samples).

ðŸ“Œ Highlights:
- Feature preprocessing and dimensionality handling
- Classifier training, tuning, and evaluation
- Output vector `labels59.npy` for submission

---

## ðŸ‘¥ Authors

- Full names and student IDs (AEMs) are included inside the notebooks and presentation.

---
